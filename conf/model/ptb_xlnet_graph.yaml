# @package _global_
d_model: 2048

encoder: xlnet-large-cased
use_tags: false
use_words: false
d_kqv: 64
d_ff: 2048
word_emb_dropout: 0.2
tag_emb_dropout: 0
relu_dropout: 0.2
residual_dropout: 0
attention_dropout: 0.2
num_attn_layers: 3
num_attn_heads: 8

decoder: graph
num_gcn_layers: 2

learning_rate: 1e-5
weight_decay: 0
subbatch_max_tokens: 700
